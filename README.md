# Chat IA Desktop

Uma aplica√ß√£o Blazor Server que permite conversar com modelos de IA usando o Ollama localmente no seu computador.

## Funcionalidades

- üí¨ Chat com modelos de IA local via Ollama
- üìÅ Upload e an√°lise de arquivos PDF e TXT
- üîç Comandos especiais (@ajuda.ai e @sentimento)
- üåô Tema escuro moderno
- üîí Processamento local (privacidade)

## Clonando o Reposit√≥rio

Para obter o c√≥digo-fonte, clone o reposit√≥rio:

```bash
git clone https://github.com/johnpaulo0602/chatIADesktop.git
cd chatIADesktop
```

## Executando localmente para Desenvolvimento

### Instalando Depend√™ncias no Windows

1. Instale o .NET 8.0 SDK:
   - Baixe o instalador do [site oficial da Microsoft](https://dotnet.microsoft.com/download/dotnet/8.0)
   - Execute o instalador e siga as instru√ß√µes na tela
   - Verifique a instala√ß√£o:
   ```cmd
   dotnet --version
   ```

2. Instale o Ollama:
   - Baixe o instalador do [site oficial do Ollama](https://ollama.ai/download/windows)
   - Execute o instalador e siga as instru√ß√µes
   - Abra o PowerShell e execute o Ollama:
   ```powershell
   ollama serve
   ```

3. Baixe um modelo de IA (em outro terminal):
   ```powershell
   ollama pull gemma3:latest
   ```

### Instalando Depend√™ncias no Linux (Fedora/Ubuntu)

1. Instale o .NET 8.0 SDK no Ubuntu/Debian:
   ```bash
   wget https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/packages-microsoft-prod.deb -O packages-microsoft-prod.deb
   sudo dpkg -i packages-microsoft-prod.deb
   rm packages-microsoft-prod.deb
   sudo apt-get update
   sudo apt-get install -y dotnet-sdk-8.0
   ```

   No Fedora:
   ```bash
   sudo dnf install dotnet-sdk-8.0
   ```

2. Instale o Ollama no Linux:
   ```bash
   curl -fsSL https://ollama.com/install.sh | sh
   ollama serve &
   ```

3. Baixe um modelo de IA:
   ```bash
   ollama pull gemma3:latest
   ```

### Executando a Aplica√ß√£o Localmente

1. Restaure as depend√™ncias:
   ```bash
   dotnet restore
   ```

2. Compile a aplica√ß√£o:
   ```bash
   dotnet build
   ```

3. Execute a aplica√ß√£o:
   ```bash
   dotnet run
   ```

4. Acesse a aplica√ß√£o em:
   - http://localhost:5000
   - https://localhost:5001

## Executando com Docker (Alternativa)

### Pr√©-requisitos
- Docker
- Docker Compose
- Placa de v√≠deo NVIDIA com drivers instalados (opcional, para acelera√ß√£o GPU)

### Passos para Execu√ß√£o

1. Construa a imagem Docker da aplica√ß√£o Blazor:
```bash
docker build -t chat-blazor .
```

2. Inicie os containers com Docker Compose:
```bash
docker-compose up -d
```

3. A aplica√ß√£o estar√° dispon√≠vel em:
   - HTTP: http://localhost:5000
   - HTTPS: https://localhost:5001

4. Baixe o modelo de IA necess√°rio:
```bash
docker exec -it ollama ollama pull gemma3:latest
```

Para baixar modelos alternativos, como o gemma3:12b:
```bash
docker exec -it ollama ollama pull gemma3:12b
```

### Parando a Aplica√ß√£o Docker

```bash
docker-compose down
```

Para remover volumes e dados:
```bash
docker-compose down -v
```

## Comandos Especiais

- `@ajuda.ai [termo]` - Explica um termo em linguagem simples (m√°x. 100 palavras)
- `@sentimento [texto]` - Analisa o sentimento de um texto (positivo/negativo/neutro)

## Modelos Recomendados

- **gemma3:latest**: Modelo padr√£o, bom equil√≠brio entre desempenho e qualidade
- **gemma3:12b**: Vers√£o maior com melhor qualidade de resposta
- **llama2**: Alternativa para hardware menos potente
- **mistral**: Bom para tarefas de gera√ß√£o de texto

## Estrutura do Projeto

- **Components/Pages**: Interfaces Blazor
- **Servicos**: L√≥gica de neg√≥cios e comunica√ß√£o com Ollama
- **Modelos**: Classes de dados
- **Utilitarios**: Ferramentas auxiliares

## Resolu√ß√£o de Problemas

- **Certificado HTTPS n√£o confi√°vel**: Adicione uma exce√ß√£o de seguran√ßa no navegador
- **Modelo n√£o carregado**: Verifique os logs: `docker logs ollama` ou `ollama logs`
- **Erro de conex√£o**: Verifique se o servi√ßo Ollama est√° rodando
- **Performance lenta**: Modelos menores como o gemma3:2b ou mistral:7b exigem menos recursos
- **Porta em uso**: Altere as portas no docker-compose.yaml ou na execu√ß√£o local

## Tecnologias Utilizadas

- .NET 8.0
- Blazor Server
- Tailwind CSS
- iText7 (para processamento de PDF)
- Ollama (API de IA local)